"""
ç¼“å­˜æ¨¡å‹åŠ è½½èŠ‚ç‚¹ - ç”¨äºåŠ è½½é¢„å¯åŠ¨é˜¶æ®µç¼“å­˜çš„æ¨¡å‹
"""
import folder_paths
import logging
from .prestartup_script import (
    get_preloaded_model,
    is_model_preloaded,
    get_all_preloaded_models,
    # æ–‡æœ¬ç¼–ç å™¨ç¼“å­˜
    get_preloaded_text_encoder,
    is_text_encoder_preloaded,
    get_all_preloaded_text_encoders,
    # æ‰©æ•£æ¨¡å‹ç¼“å­˜
    get_preloaded_diffusion_model,
    is_diffusion_model_preloaded,
    get_all_preloaded_diffusion_models,
    # VAEç¼“å­˜
    get_preloaded_vae,
    is_vae_preloaded,
    get_all_preloaded_vaes,
    preload_models
)

preload_models()

class CachedCheckpointLoader:
    """ä»é¢„åŠ è½½ç¼“å­˜ä¸­åŠ è½½æ£€æŸ¥ç‚¹æ¨¡å‹"""

    @classmethod
    def INPUT_TYPES(s):
        # è·å–æ‰€æœ‰å¯ç”¨çš„æ£€æŸ¥ç‚¹åç§°
        available_checkpoints = folder_paths.get_filename_list("checkpoints")

        return {
            "required": {
                "ckpt_name": (available_checkpoints, {"tooltip": "è¦åŠ è½½çš„æ£€æŸ¥ç‚¹æ¨¡å‹åç§°"}),
                "use_cache": ("BOOLEAN", {"default": True, "label_off": "ç›´æ¥åŠ è½½", "label_on": "ä½¿ç”¨ç¼“å­˜"}),
            },
            "optional": {
                "cache_key": ("STRING", {"multiline": False, "placeholder": "å¯é€‰ï¼šæŒ‡å®šç¼“å­˜é”®åï¼ˆç•™ç©ºåˆ™ä½¿ç”¨ckpt_nameï¼‰"}),
            }
        }

    RETURN_TYPES = ("MODEL", "CLIP", "VAE", "STRING", "BOOLEAN")
    RETURN_NAMES = ("model", "clip", "vae", "cache_info", "from_cache")
    OUTPUT_TOOLTIPS = (
        "ç”¨äºå»å™ªæ½œåœ¨ç©ºé—´çš„æ‰©æ•£æ¨¡å‹",
        "ç”¨äºç¼–ç æ–‡æœ¬æç¤ºçš„CLIPæ¨¡å‹",
        "ç”¨äºç¼–ç å’Œè§£ç å›¾åƒçš„VAEæ¨¡å‹",
        "ç¼“å­˜çŠ¶æ€ä¿¡æ¯",
        "æ˜¯å¦ä»ç¼“å­˜åŠ è½½"
    )

    FUNCTION = "load_checkpoint"
    CATEGORY = "MemorySnapshotHelper/loaders"
    DESCRIPTION = "ä»é¢„åŠ è½½ç¼“å­˜æˆ–ç›´æ¥åŠ è½½æ£€æŸ¥ç‚¹æ¨¡å‹ã€‚å¦‚æœæ¨¡å‹å·²é¢„åŠ è½½åˆ°ç¼“å­˜ä¸­ï¼Œå°†ç›´æ¥ä»ç¼“å­˜è¿”å›ï¼Œå¤§å¤§æé«˜åŠ è½½é€Ÿåº¦ã€‚"

    def load_checkpoint(self, ckpt_name, use_cache=True, cache_key=""):
        # ç¡®å®šè¦ä½¿ç”¨çš„ç¼“å­˜é”®
        key = cache_key.strip() if cache_key.strip() else ckpt_name

        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç¼“å­˜ä¸”æ¨¡å‹å·²é¢„åŠ è½½
        if use_cache and is_model_preloaded(key):
            cached_model = get_preloaded_model(key)

            model_patcher = cached_model['model_patcher']
            clip = cached_model['clip']
            vae = cached_model['vae']

            cache_info = f"âœ… ä»ç¼“å­˜åŠ è½½: {key}"
            from_cache = True

            logging.info(f"[CachedCheckpointLoader] ==> ä»ç¼“å­˜åŠ è½½æ¨¡å‹: {key}")

        else:
            # ç›´æ¥åŠ è½½æ¨¡å‹ï¼ˆåŸå§‹æ–¹å¼ï¼‰
            from comfy import sd

            ckpt_path = folder_paths.get_full_path_or_raise("checkpoints", ckpt_name)
            out = sd.load_checkpoint_guess_config(
                ckpt_path,
                output_vae=True,
                output_clip=True,
                embedding_directory=folder_paths.get_folder_paths("embeddings")
            )

            model_patcher, clip, vae = out[:3]

            if use_cache:
                cache_info = f"âš ï¸ ç¼“å­˜æœªå‘½ä¸­ï¼Œç›´æ¥åŠ è½½: {ckpt_name} (æœªé¢„åŠ è½½: {key})"
                logging.info(f"[CachedCheckpointLoader] ==> ç¼“å­˜æœªå‘½ä¸­ï¼Œç›´æ¥åŠ è½½: {ckpt_name}")
            else:
                cache_info = f"ğŸ”„ ç›´æ¥åŠ è½½æ¨¡å¼: {ckpt_name}"
                logging.info(f"[CachedCheckpointLoader] ==> ç›´æ¥åŠ è½½æ¨¡å¼: {ckpt_name}")

            from_cache = False

        return model_patcher, clip, vae, cache_info, from_cache

    @staticmethod
    def IS_CHANGED(ckpt_name, use_cache=True, cache_key=""):
        # å¦‚æœä½¿ç”¨ç¼“å­˜ä¸”æ¨¡å‹å·²é¢„åŠ è½½ï¼Œè¿”å›å›ºå®šå€¼é¿å…é‡å¤è®¡ç®—
        key = cache_key.strip() if cache_key.strip() else ckpt_name
        if use_cache and is_model_preloaded(key):
            return f"cached_{key}"
        return ckpt_name


class CachedModelInfo:
    """æ˜¾ç¤ºç¼“å­˜æ¨¡å‹ä¿¡æ¯"""

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {},
            "hidden": {"unique_id": "UNIQUE_ID"},
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("cache_info",)

    FUNCTION = "get_cache_info"
    CATEGORY = "MemorySnapshotHelper/info"
    OUTPUT_NODE = True
    DESCRIPTION = "æ˜¾ç¤ºå½“å‰é¢„åŠ è½½çš„æ¨¡å‹ç¼“å­˜ä¿¡æ¯"

    def get_cache_info(self, unique_id):
        try:
            cached_models = get_all_preloaded_models()

            if not cached_models:
                info = "âš ï¸ æ²¡æœ‰é¢„åŠ è½½çš„æ¨¡å‹ç¼“å­˜"
            else:
                info_lines = ["ğŸ“‹ é¢„åŠ è½½æ¨¡å‹ç¼“å­˜ä¿¡æ¯:", ""]

                for i, model in enumerate(cached_models, 1):
                    info_lines.append(f"{i}. æ¨¡å‹åç§°: {model['name']}")
                    info_lines.append(f"   è·¯å¾„: {model['path']}")
                    info_lines.append(f"   æ¨¡å‹: {'âœ…' if model['model_patcher'] else 'âŒ'}")
                    info_lines.append(f"   CLIP: {'âœ…' if model['clip'] else 'âŒ'}")
                    info_lines.append(f"   VAE: {'âœ…' if model['vae'] else 'âŒ'}")
                    info_lines.append("")

                info_lines.append(f"æ€»è®¡: {len(cached_models)} ä¸ªé¢„åŠ è½½æ¨¡å‹")
                info = "\n".join(info_lines)

        except Exception as e:
            info = f"âŒ è·å–ç¼“å­˜ä¿¡æ¯å¤±è´¥: {str(e)}"

        logging.info(f"[CachedModelInfo] ==> ç¼“å­˜ä¿¡æ¯: {len(get_all_preloaded_models())} ä¸ªæ¨¡å‹")
        return (info,)

    @classmethod
    def IS_CHANGED(cls, **kwargs):
        # æ€»æ˜¯æ›´æ–°ä»¥æ˜¾ç¤ºæœ€æ–°ä¿¡æ¯
        return float("NaN")


class PreloadedModelSelector:
    """é¢„åŠ è½½æ¨¡å‹é€‰æ‹©å™¨ - åªæ˜¾ç¤ºå·²é¢„åŠ è½½çš„æ¨¡å‹"""

    @classmethod
    def INPUT_TYPES(s):
        # è·å–é¢„åŠ è½½æ¨¡å‹åˆ—è¡¨
        preloaded_models = [model['name'] for model in get_all_preloaded_models()]

        if not preloaded_models:
            preloaded_models = ["æ— é¢„åŠ è½½æ¨¡å‹"]

        return {
            "required": {
                "model_name": (preloaded_models, {"tooltip": "é€‰æ‹©ä¸€ä¸ªé¢„åŠ è½½çš„æ¨¡å‹"}),
            }
        }

    RETURN_TYPES = ("MODEL", "CLIP", "VAE", "STRING")
    RETURN_NAMES = ("model", "clip", "vae", "model_name")
    OUTPUT_TOOLTIPS = (
        "é¢„åŠ è½½çš„æ‰©æ•£æ¨¡å‹",
        "é¢„åŠ è½½çš„CLIPæ¨¡å‹",
        "é¢„åŠ è½½çš„VAEæ¨¡å‹",
        "æ¨¡å‹åç§°"
    )

    FUNCTION = "load_preloaded_model"
    CATEGORY = "MemorySnapshotHelper/loaders"
    DESCRIPTION = "ä»é¢„åŠ è½½çš„æ¨¡å‹ç¼“å­˜ä¸­é€‰æ‹©å¹¶åŠ è½½æ¨¡å‹ï¼Œç¡®ä¿å¿«é€Ÿè®¿é—®ã€‚"

    def load_preloaded_model(self, model_name):
        if model_name == "æ— é¢„åŠ è½½æ¨¡å‹":
            raise Exception("æ²¡æœ‰å¯ç”¨çš„é¢„åŠ è½½æ¨¡å‹ã€‚è¯·ç¡®ä¿åœ¨é¢„å¯åŠ¨è„šæœ¬ä¸­é…ç½®äº†è¦é¢„åŠ è½½çš„æ¨¡å‹ã€‚")

        cached_model = get_preloaded_model(model_name)

        if cached_model is None:
            raise Exception(f"æ¨¡å‹ '{model_name}' æœªåœ¨ç¼“å­˜ä¸­æ‰¾åˆ°")

        model_patcher = cached_model['model_patcher']
        clip = cached_model['clip']
        vae = cached_model['vae']

        logging.info(f"[PreloadedModelSelector] ==> åŠ è½½é¢„ç¼“å­˜æ¨¡å‹: {model_name}")

        return model_patcher, clip, vae, model_name

    @staticmethod
    def IS_CHANGED(model_name):
        # å¯¹äºé¢„åŠ è½½æ¨¡å‹ï¼Œè¿”å›å›ºå®šå€¼é¿å…é‡å¤è®¡ç®—
        if model_name != "æ— é¢„åŠ è½½æ¨¡å‹":
            return f"preloaded_{model_name}"
        return model_name


class CheckCacheStatus:
    """æ£€æŸ¥ç‰¹å®šæ¨¡å‹çš„ç¼“å­˜çŠ¶æ€"""

    @classmethod
    def INPUT_TYPES(s):
        available_checkpoints = folder_paths.get_filename_list("checkpoints")
        return {
            "required": {
                "ckpt_name": (available_checkpoints, {"tooltip": "è¦æ£€æŸ¥çš„æ£€æŸ¥ç‚¹æ¨¡å‹åç§°"}),
            },
            "optional": {
                "cache_key": ("STRING", {"multiline": False, "placeholder": "å¯é€‰ï¼šæŒ‡å®šç¼“å­˜é”®å"}),
            }
        }

    RETURN_TYPES = ("BOOLEAN", "STRING")
    RETURN_NAMES = ("is_cached", "status_info")
    OUTPUT_TOOLTIPS = (
        "æ¨¡å‹æ˜¯å¦å·²ç¼“å­˜",
        "ç¼“å­˜çŠ¶æ€ä¿¡æ¯"
    )

    FUNCTION = "check_cache_status"
    CATEGORY = "MemorySnapshotHelper/info"
    DESCRIPTION = "æ£€æŸ¥æŒ‡å®šæ¨¡å‹æ˜¯å¦å·²é¢„åŠ è½½åˆ°ç¼“å­˜ä¸­"

    def check_cache_status(self, ckpt_name, cache_key=""):
        key = cache_key.strip() if cache_key.strip() else ckpt_name

        is_cached = is_model_preloaded(key)

        if is_cached:
            cached_model = get_preloaded_model(key)
            status_info = f"âœ… æ¨¡å‹å·²ç¼“å­˜: {key}\nè·¯å¾„: {cached_model['path']}"
        else:
            status_info = f"âŒ æ¨¡å‹æœªç¼“å­˜: {key}"

        return is_cached, status_info

    @staticmethod
    def IS_CHANGED(ckpt_name, cache_key=""):
        key = cache_key.strip() if cache_key.strip() else ckpt_name
        return f"check_{key}"


class CachedTextEncoderLoader:
    """ä»é¢„åŠ è½½ç¼“å­˜ä¸­åŠ è½½æ–‡æœ¬ç¼–ç å™¨"""

    @classmethod
    def INPUT_TYPES(s):
        available_text_encoders = folder_paths.get_filename_list("text_encoders")

        return {
            "required": {
                "clip_name1": (available_text_encoders, {"tooltip": "ç¬¬ä¸€ä¸ªæ–‡æœ¬ç¼–ç å™¨åç§°"}),
                "type": (["stable_diffusion", "stable_cascade", "sd3", "stable_audio", "mochi", "ltxv", "pixart", "cosmos","lumina2","wan","hidream","chroma","ace","omnigen2","qwen_image"], ),
                "use_cache": ("BOOLEAN", {"default": True, "label_off": "ç›´æ¥åŠ è½½", "label_on": "ä½¿ç”¨ç¼“å­˜"}),
            },
            "optional": {
                "clip_name2": (["None"] + available_text_encoders, ),
                "clip_name3": (["None"] + available_text_encoders, ),
                "device": (["default", "cpu"], {"advanced": True}),
                "cache_key": ("STRING", {"multiline": False, "placeholder": "å¯é€‰ï¼šæŒ‡å®šç¼“å­˜é”®å"}),
            }
        }

    RETURN_TYPES = ("CLIP", "STRING", "BOOLEAN")
    RETURN_NAMES = ("clip", "cache_info", "from_cache")
    OUTPUT_TOOLTIPS = (
        "åŠ è½½çš„CLIPæ¨¡å‹",
        "ç¼“å­˜çŠ¶æ€ä¿¡æ¯",
        "æ˜¯å¦ä»ç¼“å­˜åŠ è½½"
    )

    FUNCTION = "load_text_encoder"
    CATEGORY = "MemorySnapshotHelper/loaders"
    DESCRIPTION = "ä»é¢„åŠ è½½ç¼“å­˜æˆ–ç›´æ¥åŠ è½½æ–‡æœ¬ç¼–ç å™¨ã€‚æ”¯æŒå•ä¸ªã€åŒé‡æˆ–ä¸‰é‡æ–‡æœ¬ç¼–ç å™¨ã€‚"

    def load_text_encoder(self, clip_name1, type, use_cache=True, clip_name2="None", clip_name3="None", device="default", cache_key=""):
        # æ„å»ºç¼“å­˜é”®
        if cache_key.strip():
            key = cache_key.strip()
        else:
            key = clip_name1
            if clip_name2 != "None":
                key += f"_{clip_name2}"
            if clip_name3 != "None":
                key += f"_{clip_name3}"
            key += f"_{type}_{device}"

        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç¼“å­˜ä¸”ç¼–ç å™¨å·²é¢„åŠ è½½
        if use_cache and is_text_encoder_preloaded(key):
            cached_encoder = get_preloaded_text_encoder(key)
            clip = cached_encoder['clip']

            cache_info = f"âœ… ä»ç¼“å­˜åŠ è½½æ–‡æœ¬ç¼–ç å™¨: {key}"
            from_cache = True

            logging.info(f"[CachedTextEncoderLoader] ==> ä»ç¼“å­˜åŠ è½½æ–‡æœ¬ç¼–ç å™¨: {key}")

        else:
            # ç›´æ¥åŠ è½½ç¼–ç å™¨
            import nodes

            # æ ¹æ®ç¼–ç å™¨æ•°é‡é€‰æ‹©åŠ è½½æ–¹å¼
            clip_name_list = [name for name in [clip_name1, clip_name2, clip_name3] if name != "None"]

            if len(clip_name_list) == 1:
                clip = nodes.CLIPLoader().load_clip(clip_name1, type=type, device=device)[0]
            elif len(clip_name_list) == 2:
                clip = nodes.DualCLIPLoader().load_clip(clip_name1, clip_name_list[1], type=type, device=device)[0]
            elif len(clip_name_list) == 3:
                if "TripleCLIPLoader" in nodes.NODE_CLASS_MAPPINGS:
                    clip = nodes.NODE_CLASS_MAPPINGS["TripleCLIPLoader"]().load_clip(clip_name1, clip_name_list[1], clip_name_list[2])[0]
                else:
                    raise Exception("TripleCLIPLoader ä¸å¯ç”¨")
            else:
                raise Exception(f"ä¸æ”¯æŒçš„æ–‡æœ¬ç¼–ç å™¨æ•°é‡: {len(clip_name_list)}")

            if use_cache:
                cache_info = f"âš ï¸ ç¼“å­˜æœªå‘½ä¸­ï¼Œç›´æ¥åŠ è½½: {key}"
                logging.info(f"[CachedTextEncoderLoader] ==> ç¼“å­˜æœªå‘½ä¸­ï¼Œç›´æ¥åŠ è½½: {key}")
            else:
                cache_info = f"ğŸ”„ ç›´æ¥åŠ è½½æ¨¡å¼: {key}"
                logging.info(f"[CachedTextEncoderLoader] ==> ç›´æ¥åŠ è½½æ¨¡å¼: {key}")

            from_cache = False

        return clip, cache_info, from_cache

    @staticmethod
    def IS_CHANGED(clip_name1, type, use_cache=True, clip_name2="None", clip_name3="None", device="default", cache_key=""):
        # æ„å»ºç¼“å­˜é”®
        if cache_key.strip():
            key = cache_key.strip()
        else:
            key = clip_name1
            if clip_name2 != "None":
                key += f"_{clip_name2}"
            if clip_name3 != "None":
                key += f"_{clip_name3}"
            key += f"_{type}_{device}"

        if use_cache and is_text_encoder_preloaded(key):
            return f"cached_te_{key}"
        return f"te_{clip_name1}_{clip_name2}_{clip_name3}_{type}_{device}"


class CachedDiffusionModelLoader:
    """ä»é¢„åŠ è½½ç¼“å­˜ä¸­åŠ è½½æ‰©æ•£æ¨¡å‹"""

    @classmethod
    def INPUT_TYPES(s):
        available_models = folder_paths.get_filename_list("diffusion_models")

        return {
            "required": {
                "model_name": (available_models, {"tooltip": "æ‰©æ•£æ¨¡å‹åç§°"}),
                "weight_dtype": (["default", "fp8_e4m3fn", "fp8_e4m3fn_fast", "fp8_e5m2"],),
                "use_cache": ("BOOLEAN", {"default": True, "label_off": "ç›´æ¥åŠ è½½", "label_on": "ä½¿ç”¨ç¼“å­˜"}),
            },
            "optional": {
                "cache_key": ("STRING", {"multiline": False, "placeholder": "å¯é€‰ï¼šæŒ‡å®šç¼“å­˜é”®å"}),
            }
        }

    RETURN_TYPES = ("MODEL", "STRING", "BOOLEAN")
    RETURN_NAMES = ("model", "cache_info", "from_cache")
    OUTPUT_TOOLTIPS = (
        "åŠ è½½çš„æ‰©æ•£æ¨¡å‹",
        "ç¼“å­˜çŠ¶æ€ä¿¡æ¯",
        "æ˜¯å¦ä»ç¼“å­˜åŠ è½½"
    )

    FUNCTION = "load_diffusion_model"
    CATEGORY = "MemorySnapshotHelper/loaders"
    DESCRIPTION = "ä»é¢„åŠ è½½ç¼“å­˜æˆ–ç›´æ¥åŠ è½½æ‰©æ•£æ¨¡å‹ã€‚"

    def load_diffusion_model(self, model_name, weight_dtype, use_cache=True, cache_key=""):
        # æ„å»ºç¼“å­˜é”®
        key = cache_key.strip() if cache_key.strip() else f"{model_name}_{weight_dtype}"

        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç¼“å­˜ä¸”æ¨¡å‹å·²é¢„åŠ è½½
        if use_cache and is_diffusion_model_preloaded(key):
            cached_model = get_preloaded_diffusion_model(key)
            model = cached_model['model']

            cache_info = f"âœ… ä»ç¼“å­˜åŠ è½½æ‰©æ•£æ¨¡å‹: {key}"
            from_cache = True

            logging.info(f"[CachedDiffusionModelLoader] ==> ä»ç¼“å­˜åŠ è½½æ‰©æ•£æ¨¡å‹: {key}")

        else:
            # ç›´æ¥åŠ è½½æ¨¡å‹
            import nodes

            model = nodes.UNETLoader().load_unet(model_name, weight_dtype)[0]

            if use_cache:
                cache_info = f"âš ï¸ ç¼“å­˜æœªå‘½ä¸­ï¼Œç›´æ¥åŠ è½½: {model_name} (æœªé¢„åŠ è½½: {key})"
                logging.info(f"[CachedDiffusionModelLoader] ==> ç¼“å­˜æœªå‘½ä¸­ï¼Œç›´æ¥åŠ è½½: {model_name}")
            else:
                cache_info = f"ğŸ”„ ç›´æ¥åŠ è½½æ¨¡å¼: {model_name}"
                logging.info(f"[CachedDiffusionModelLoader] ==> ç›´æ¥åŠ è½½æ¨¡å¼: {model_name}")

            from_cache = False

        return model, cache_info, from_cache

    @staticmethod
    def IS_CHANGED(model_name, weight_dtype, use_cache=True, cache_key=""):
        key = cache_key.strip() if cache_key.strip() else f"{model_name}_{weight_dtype}"
        if use_cache and is_diffusion_model_preloaded(key):
            return f"cached_dm_{key}"
        return f"dm_{model_name}_{weight_dtype}"


class PreloadedTextEncoderSelector:
    """é¢„åŠ è½½æ–‡æœ¬ç¼–ç å™¨é€‰æ‹©å™¨"""

    @classmethod
    def INPUT_TYPES(s):
        preloaded_encoders = get_all_preloaded_text_encoders()
        encoder_keys = [encoder['key'] for encoder in preloaded_encoders]

        if not encoder_keys:
            encoder_keys = ["æ— é¢„åŠ è½½æ–‡æœ¬ç¼–ç å™¨"]

        return {
            "required": {
                "encoder_key": (encoder_keys, {"tooltip": "é€‰æ‹©ä¸€ä¸ªé¢„åŠ è½½çš„æ–‡æœ¬ç¼–ç å™¨"}),
            }
        }

    RETURN_TYPES = ("CLIP", "STRING")
    RETURN_NAMES = ("clip", "encoder_info")
    OUTPUT_TOOLTIPS = (
        "é¢„åŠ è½½çš„CLIPæ¨¡å‹",
        "ç¼–ç å™¨ä¿¡æ¯"
    )

    FUNCTION = "load_preloaded_text_encoder"
    CATEGORY = "MemorySnapshotHelper/loaders"
    DESCRIPTION = "ä»é¢„åŠ è½½çš„æ–‡æœ¬ç¼–ç å™¨ç¼“å­˜ä¸­é€‰æ‹©å¹¶åŠ è½½ç¼–ç å™¨ã€‚"

    def load_preloaded_text_encoder(self, encoder_key):
        if encoder_key == "æ— é¢„åŠ è½½æ–‡æœ¬ç¼–ç å™¨":
            raise Exception("æ²¡æœ‰å¯ç”¨çš„é¢„åŠ è½½æ–‡æœ¬ç¼–ç å™¨ã€‚è¯·ç¡®ä¿åœ¨é¢„å¯åŠ¨è„šæœ¬ä¸­é…ç½®äº†è¦é¢„åŠ è½½çš„æ–‡æœ¬ç¼–ç å™¨ã€‚")

        cached_encoder = get_preloaded_text_encoder(encoder_key)

        if cached_encoder is None:
            raise Exception(f"æ–‡æœ¬ç¼–ç å™¨ '{encoder_key}' æœªåœ¨ç¼“å­˜ä¸­æ‰¾åˆ°")

        clip = cached_encoder['clip']
        encoder_info = f"ç±»å‹: {cached_encoder['clip_type']}, è®¾å¤‡: {cached_encoder['device']}, åç§°: {cached_encoder['clip_names']}"

        logging.info(f"[PreloadedTextEncoderSelector] ==> åŠ è½½é¢„ç¼“å­˜æ–‡æœ¬ç¼–ç å™¨: {encoder_key}")

        return clip, encoder_info

    @staticmethod
    def IS_CHANGED(encoder_key):
        if encoder_key != "æ— é¢„åŠ è½½æ–‡æœ¬ç¼–ç å™¨":
            return f"preloaded_te_{encoder_key}"
        return encoder_key


class PreloadedDiffusionModelSelector:
    """é¢„åŠ è½½æ‰©æ•£æ¨¡å‹é€‰æ‹©å™¨"""

    @classmethod
    def INPUT_TYPES(s):
        preloaded_models = get_all_preloaded_diffusion_models()
        model_keys = [model['key'] for model in preloaded_models]

        if not model_keys:
            model_keys = ["æ— é¢„åŠ è½½æ‰©æ•£æ¨¡å‹"]

        return {
            "required": {
                "model_key": (model_keys, {"tooltip": "é€‰æ‹©ä¸€ä¸ªé¢„åŠ è½½çš„æ‰©æ•£æ¨¡å‹"}),
            }
        }

    RETURN_TYPES = ("MODEL", "STRING")
    RETURN_NAMES = ("model", "model_info")
    OUTPUT_TOOLTIPS = (
        "é¢„åŠ è½½çš„æ‰©æ•£æ¨¡å‹",
        "æ¨¡å‹ä¿¡æ¯"
    )

    FUNCTION = "load_preloaded_diffusion_model"
    CATEGORY = "MemorySnapshotHelper/loaders"
    DESCRIPTION = "ä»é¢„åŠ è½½çš„æ‰©æ•£æ¨¡å‹ç¼“å­˜ä¸­é€‰æ‹©å¹¶åŠ è½½æ¨¡å‹ã€‚"

    def load_preloaded_diffusion_model(self, model_key):
        if model_key == "æ— é¢„åŠ è½½æ‰©æ•£æ¨¡å‹":
            raise Exception("æ²¡æœ‰å¯ç”¨çš„é¢„åŠ è½½æ‰©æ•£æ¨¡å‹ã€‚è¯·ç¡®ä¿åœ¨é¢„å¯åŠ¨è„šæœ¬ä¸­é…ç½®äº†è¦é¢„åŠ è½½çš„æ‰©æ•£æ¨¡å‹ã€‚")

        cached_model = get_preloaded_diffusion_model(model_key)

        if cached_model is None:
            raise Exception(f"æ‰©æ•£æ¨¡å‹ '{model_key}' æœªåœ¨ç¼“å­˜ä¸­æ‰¾åˆ°")

        model = cached_model['model']
        model_info = f"æ¨¡å‹åç§°: {cached_model['model_name']}, æƒé‡ç±»å‹: {cached_model['weight_dtype']}"

        logging.info(f"[PreloadedDiffusionModelSelector] ==> åŠ è½½é¢„ç¼“å­˜æ‰©æ•£æ¨¡å‹: {model_key}")

        return model, model_info

    @staticmethod
    def IS_CHANGED(model_key):
        if model_key != "æ— é¢„åŠ è½½æ‰©æ•£æ¨¡å‹":
            return f"preloaded_dm_{model_key}"
        return model_key


class CachedVAELoader:
    """ä»é¢„åŠ è½½ç¼“å­˜ä¸­åŠ è½½VAE"""

    @classmethod
    def INPUT_TYPES(s):
        available_vaes = folder_paths.get_filename_list("vae")

        return {
            "required": {
                "vae_name": (available_vaes, {"tooltip": "VAEæ¨¡å‹åç§°"}),
                "use_cache": ("BOOLEAN", {"default": True, "label_off": "ç›´æ¥åŠ è½½", "label_on": "ä½¿ç”¨ç¼“å­˜"}),
            },
            "optional": {
                "cache_key": ("STRING", {"multiline": False, "placeholder": "å¯é€‰ï¼šæŒ‡å®šç¼“å­˜é”®å"}),
            }
        }

    RETURN_TYPES = ("VAE", "STRING", "BOOLEAN")
    RETURN_NAMES = ("vae", "cache_info", "from_cache")
    OUTPUT_TOOLTIPS = (
        "åŠ è½½çš„VAEæ¨¡å‹",
        "ç¼“å­˜çŠ¶æ€ä¿¡æ¯",
        "æ˜¯å¦ä»ç¼“å­˜åŠ è½½"
    )

    FUNCTION = "load_vae"
    CATEGORY = "MemorySnapshotHelper/loaders"
    DESCRIPTION = "ä»é¢„åŠ è½½ç¼“å­˜æˆ–ç›´æ¥åŠ è½½VAEæ¨¡å‹ã€‚"

    def load_vae(self, vae_name, use_cache=True, cache_key=""):
        # æ„å»ºç¼“å­˜é”®
        key = cache_key.strip() if cache_key.strip() else vae_name

        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç¼“å­˜ä¸”VAEå·²é¢„åŠ è½½
        if use_cache and is_vae_preloaded(key):
            cached_vae = get_preloaded_vae(key)
            vae = cached_vae['vae']

            cache_info = f"âœ… ä»ç¼“å­˜åŠ è½½VAE: {key}"
            from_cache = True

            logging.info(f"[CachedVAELoader] ==> ä»ç¼“å­˜åŠ è½½VAE: {key}")

        else:
            # ç›´æ¥åŠ è½½VAE
            import nodes

            vae = nodes.VAELoader().load_vae(vae_name)[0]

            if use_cache:
                cache_info = f"âš ï¸ ç¼“å­˜æœªå‘½ä¸­ï¼Œç›´æ¥åŠ è½½: {vae_name} (æœªé¢„åŠ è½½: {key})"
                logging.info(f"[CachedVAELoader] ==> ç¼“å­˜æœªå‘½ä¸­ï¼Œç›´æ¥åŠ è½½: {vae_name}")
            else:
                cache_info = f"ğŸ”„ ç›´æ¥åŠ è½½æ¨¡å¼: {vae_name}"
                logging.info(f"[CachedVAELoader] ==> ç›´æ¥åŠ è½½æ¨¡å¼: {vae_name}")

            from_cache = False

        return vae, cache_info, from_cache

    @staticmethod
    def IS_CHANGED(vae_name, use_cache=True, cache_key=""):
        key = cache_key.strip() if cache_key.strip() else vae_name
        if use_cache and is_vae_preloaded(key):
            return f"cached_vae_{key}"
        return f"vae_{vae_name}"


class PreloadedVAESelector:
    """é¢„åŠ è½½VAEé€‰æ‹©å™¨"""

    @classmethod
    def INPUT_TYPES(s):
        preloaded_vaes = get_all_preloaded_vaes()
        vae_names = [vae['name'] for vae in preloaded_vaes]

        if not vae_names:
            vae_names = ["æ— é¢„åŠ è½½VAE"]

        return {
            "required": {
                "vae_name": (vae_names, {"tooltip": "é€‰æ‹©ä¸€ä¸ªé¢„åŠ è½½çš„VAE"}),
            }
        }

    RETURN_TYPES = ("VAE", "STRING")
    RETURN_NAMES = ("vae", "vae_info")
    OUTPUT_TOOLTIPS = (
        "é¢„åŠ è½½çš„VAEæ¨¡å‹",
        "VAEä¿¡æ¯"
    )

    FUNCTION = "load_preloaded_vae"
    CATEGORY = "MemorySnapshotHelper/loaders"
    DESCRIPTION = "ä»é¢„åŠ è½½çš„VAEç¼“å­˜ä¸­é€‰æ‹©å¹¶åŠ è½½VAEã€‚"

    def load_preloaded_vae(self, vae_name):
        if vae_name == "æ— é¢„åŠ è½½VAE":
            raise Exception("æ²¡æœ‰å¯ç”¨çš„é¢„åŠ è½½VAEã€‚è¯·ç¡®ä¿åœ¨é¢„å¯åŠ¨è„šæœ¬ä¸­é…ç½®äº†è¦é¢„åŠ è½½çš„VAEã€‚")

        cached_vae = get_preloaded_vae(vae_name)

        if cached_vae is None:
            raise Exception(f"VAE '{vae_name}' æœªåœ¨ç¼“å­˜ä¸­æ‰¾åˆ°")

        vae = cached_vae['vae']
        vae_info = f"VAEåç§°: {cached_vae['name']}"

        logging.info(f"[PreloadedVAESelector] ==> åŠ è½½é¢„ç¼“å­˜VAE: {vae_name}")

        return vae, vae_info

    @staticmethod
    def IS_CHANGED(vae_name):
        if vae_name != "æ— é¢„åŠ è½½VAE":
            return f"preloaded_vae_{vae_name}"
        return vae_name


# èŠ‚ç‚¹ç±»æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "CachedCheckpointLoader": CachedCheckpointLoader,
    "CachedModelInfo": CachedModelInfo,
    "PreloadedModelSelector": PreloadedModelSelector,
    "CheckCacheStatus": CheckCacheStatus,
    "CachedTextEncoderLoader": CachedTextEncoderLoader,
    "CachedDiffusionModelLoader": CachedDiffusionModelLoader,
    "PreloadedTextEncoderSelector": PreloadedTextEncoderSelector,
    "PreloadedDiffusionModelSelector": PreloadedDiffusionModelSelector,
    "CachedVAELoader": CachedVAELoader,
    "PreloadedVAESelector": PreloadedVAESelector,
}

# èŠ‚ç‚¹æ˜¾ç¤ºåç§°æ˜ å°„
NODE_DISPLAY_NAME_MAPPINGS = {
    "CachedCheckpointLoader": "ğŸš€ ç¼“å­˜æ£€æŸ¥ç‚¹åŠ è½½å™¨",
    "CachedModelInfo": "ğŸ“‹ ç¼“å­˜æ¨¡å‹ä¿¡æ¯",
    "PreloadedModelSelector": "ğŸ¯ é¢„åŠ è½½æ¨¡å‹é€‰æ‹©å™¨",
    "CheckCacheStatus": "ğŸ” æ£€æŸ¥ç¼“å­˜çŠ¶æ€",
    "CachedTextEncoderLoader": "ğŸ“ ç¼“å­˜æ–‡æœ¬ç¼–ç å™¨åŠ è½½å™¨",
    "CachedDiffusionModelLoader": "ğŸ¨ ç¼“å­˜æ‰©æ•£æ¨¡å‹åŠ è½½å™¨",
    "PreloadedTextEncoderSelector": "ğŸ“ é¢„åŠ è½½æ–‡æœ¬ç¼–ç å™¨é€‰æ‹©å™¨",
    "PreloadedDiffusionModelSelector": "ğŸ¨ é¢„åŠ è½½æ‰©æ•£æ¨¡å‹é€‰æ‹©å™¨",
    "CachedVAELoader": "ğŸ–¼ï¸ ç¼“å­˜VAEåŠ è½½å™¨",
    "PreloadedVAESelector": "ğŸ–¼ï¸ é¢„åŠ è½½VAEé€‰æ‹©å™¨",
}
